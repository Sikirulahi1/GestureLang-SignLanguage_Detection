{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9e8f77f",
   "metadata": {},
   "source": [
    "# Pseudocode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090307f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an webcam to show a video\n",
    "# Capture the hand\n",
    "    # We install the mediapipe library\n",
    "    # We use the hand and drawing utils in the mediapipe.solutions library\n",
    "    # We loop through the mp_hand obtained earier to be able to use the hand function\n",
    "    # We set use the hand and drawing utils to capture the hand\n",
    "        # We first convert the video to RGB\n",
    "        # We train the frame\n",
    "        # Convert it back to BGR\n",
    "        # We draw using the landmarks obtained from the result and the connections obtained from the drawing_tils\n",
    "\n",
    "# Obtain the landmarks in a list\n",
    "    # We first obtain the landmark from hand_landmarks.landmark, we use loop to get the x, y, z and visibility\n",
    "    # We cnvert it to an array\n",
    "    # We apply the list function to convert it to a list\n",
    "# Save the landmarks in a csv file (I'll save it for each class)\n",
    "    # We will first create a row for the file using list comprehension.\n",
    "    # We will then save it to our csv file using the csv module (csv.writerow())\n",
    "    # As each frame in the video runs, it will get the landmarks to be equal to the lenght of the column in the row as a list\n",
    "    # We will then append the list of the landmarks into the csv file as each frame runs\n",
    "    # There are 21 landmarks on the human hand\n",
    "    # Ther will be (x, y, z, visibility) making 84 elements in the list\n",
    "    # If we add the class names it will make 85 in total.\n",
    "    \n",
    "# Train it\n",
    "    # For training, i will use the random forrest, logistic regression, ridge classifier and gradient boosting classifier.\n",
    "    # The rest are the normal machine learning training steps\n",
    "# Predict the class for which the hand posture belongs to.\n",
    "    # We will first get the saved file from the pre trained model\n",
    "    # We will now apply it in the main detection video webcam to predict it.\n",
    "    # Once it has been predicted, we will use the opencv library to show it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "449f979d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2 as cv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54dac442",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing_styles = mp.solutions.drawing_styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d5c87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "with mp_hands.Hands(min_detection_confidence= 0.3, min_tracking_confidence= 0.3) as hands:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # convert the color of the image to RGB\n",
    "        image = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Render detection by passing it into the model\n",
    "        results = hands.process(image)\n",
    "        \n",
    "        # Convert it back to BGR\n",
    "        image = cv.cvtColor(image, cv.COLOR_RGB2BGR)\n",
    "        \n",
    "        try:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image,\n",
    "                    hand_landmarks,\n",
    "                    mp_hands.HAND_CONNECTIONS,\n",
    "                    mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                    mp_drawing_styles.get_default_hand_connections_style())\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        cv.imshow(\"Window\", image)\n",
    "        if cv.waitKey(10) & 0xFF ==ord('q'):\n",
    "            break\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423b364c",
   "metadata": {},
   "outputs": [],
   "source": [
    "number = len(hand_landmarks.landmark)\n",
    "number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c129a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(np.array([[land.x, land.y, land.z, land.visibility] for land in hand_landmarks.landmark]).flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52af1b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_list = ['className']\n",
    "for i in range(1, number+1):\n",
    "    num_list += [f\"x{i}\", f\"y{i}\", f\"z{i}\", f\"v{i}\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42616d62",
   "metadata": {},
   "source": [
    "# Adding landmarks to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9b5bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "className = 'A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f502f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "with mp_hands.Hands(min_detection_confidence= 0.3, min_tracking_confidence= 0.3) as hands:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # convert the color of the image to RGB\n",
    "        image = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Render detection by passing it into the model\n",
    "        results = hands.process(image)\n",
    "        \n",
    "        # Convert it back to BGR\n",
    "        image = cv.cvtColor(image, cv.COLOR_RGB2BGR)\n",
    "        \n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image,\n",
    "                    hand_landmarks,\n",
    "                    mp_hands.HAND_CONNECTIONS,\n",
    "                    mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                    mp_drawing_styles.get_default_hand_connections_style())\n",
    "                \n",
    "\n",
    "        handlandm = hand_landmarks.landmark\n",
    "        hand_row = list(np.array([[land.x, land.y, land.z, land.visibility] for land in handlandm]).flatten())\n",
    "        hand_row.insert(0, className)\n",
    "\n",
    "        with open(\"signLang.csv\", mode = \"a\", newline= '') as f:\n",
    "            csv_writer = csv.writer(f, delimiter =',', quotechar = '\"', quoting = csv.QUOTE_MINIMAL)\n",
    "            csv_writer.writerow(hand_row)\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        cv.imshow(\"Window\", image)\n",
    "        if cv.waitKey(10) & 0xFF ==ord('q'):\n",
    "            break\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193b66d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32be0d1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79553bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv.VideoCapture(0)\n",
    "\n",
    "# with mp_holistics.Holistic(min_detection_confidence= 0.3, min_tracking_confidence= 0.3) as holistics:\n",
    "#     while cap.isOpened():\n",
    "#         ret, frame = cap.read()\n",
    "\n",
    "#         # convert the color of the image to RGB\n",
    "#         image = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "        \n",
    "#         # Render detection by passing it into the model\n",
    "#         results = holistics.process(image)\n",
    "        \n",
    "#         # Convert it back to BGR\n",
    "#         image = cv.cvtColor(image, cv.COLOR_RGB2BGR)\n",
    "        \n",
    "        \n",
    "#         # Draw landmarks (left_hand_landmarks and right_hand_landmarks)\n",
    "#         # left hand\n",
    "#         mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistics.HAND_CONNECTIONS)\n",
    "#         # right hand\n",
    "#         mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistics.HAND_CONNECTIONS)\n",
    "        \n",
    "        \n",
    "#         try:\n",
    "#             # Lets add the both landmarks together\n",
    "#             # For left hand \n",
    "#             left_hand = results.left_hand_landmarks.landmark\n",
    "#             left_row = list(np.array([[landmarks.x, landmarks.y, landmarks.z, landmarks.visibility] for landmarks in left_hand]).flatten())\n",
    "            \n",
    "#             # For right hand\n",
    "#             right_hand = results.right_hand_landmarks.landmark\n",
    "#             right_row = list(np.array([[landmarks.x, landmarks.y, landmarks.z, landmarks.visibility] for landmarks in right_hand]).flatten())\n",
    "            \n",
    "#             # Adding the two list together\n",
    "#             landm = left_row + right_row\n",
    "            \n",
    "#             # Inserting the class name at the first row\n",
    "#             landm.insert(0, class_name)\n",
    "            \n",
    "#             # Putting each and every parameter the csv file\n",
    "#             with open(\"train.csv\", mode='a', newline= '') as f:\n",
    "#                 csv_writer = csv.writer(f, delimiter = ',', quotechar = '\"', quoting = csv.QUOTE_MINIMAL)\n",
    "#                 csv_writer.writerow(landm)\n",
    "#         except:\n",
    "#             pass\n",
    "        \n",
    "\n",
    "\n",
    "#         cv.imshow(\"Window\", image)\n",
    "#         if cv.waitKey(10) & 0xFF ==ord('q'):\n",
    "#             break\n",
    "# cap.release()\n",
    "# cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
